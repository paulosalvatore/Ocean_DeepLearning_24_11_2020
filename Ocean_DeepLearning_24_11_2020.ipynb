{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ocean_DeepLearning_24_11_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaxqnICNrKzqYlOVYumyKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulosalvatore/Ocean_DeepLearning_24_11_2020/blob/main/Ocean_DeepLearning_24_11_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coqd5OzBKuy2"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist # Base de dados MNIST\n",
        "from tensorflow.python.keras import Sequential # Modelo da nossa rede neural\n",
        "from tensorflow.python.keras.layers import Dense, Dropout # Neurônios (base da rede) e Regularizador (evita overfitting)\n",
        "from tensorflow.compat.v1.keras.optimizers import RMSprop # Otimizador (back propagation)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw76CVoRLlAm"
      },
      "source": [
        "# Carregando os dados de treino e teste\n",
        "\n",
        "(x_treino, y_treino), (x_teste, y_teste) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1rvJ3HIOBbL",
        "outputId": "ecbb1641-f2aa-4b7a-dcf7-b8aa42362e15"
      },
      "source": [
        "print(\"Quantidade de imagens para treino:\", len(x_treino))\n",
        "\n",
        "print(\"Quantidade de imagens para teste:\", len(x_teste))\n",
        "\n",
        "print(\"Tipo de x_treino:\", type(x_treino))\n",
        "\n",
        "primeira_imagem = x_treino[0]\n",
        "\n",
        "representacao_primeira_imagem = y_treino[0]\n",
        "print(\"O que a imagem 0 representa:\", representacao_primeira_imagem)\n",
        "\n",
        "print(\"Formato da primeira imagem:\", primeira_imagem.shape, type(primeira_imagem.shape))\n",
        "\n",
        "print(primeira_imagem)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de imagens para treino: 60000\n",
            "Quantidade de imagens para teste: 10000\n",
            "Tipo de x_treino: <class 'numpy.ndarray'>\n",
            "O que a imagem 0 representa: 5\n",
            "Formato da primeira imagem: (28, 28) <class 'tuple'>\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8--r-dxsSEkT",
        "outputId": "6e77e898-4651-4b5a-f737-843fbd9d9a37"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\"\n",
        "for indice in range(60000):\n",
        "  print(\"Essa imagem representa:\", y_treino[indice])\n",
        "  plt.imshow(x_treino[indice], cmap=plt.cm.binary)\n",
        "  plt.show()\n",
        "\"\"\"\n",
        "\n",
        "indice = 5000\n",
        "\n",
        "print(\"Essa imagem representa:\", y_treino[indice])\n",
        "plt.imshow(x_treino[indice], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Essa imagem representa: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrngPs6VYCGz"
      },
      "source": [
        "# Fluxo para construção da rede neural\n",
        "# - Organizar camada de entrada (input)\n",
        "# - Organizar camada de saída (output)\n",
        "# - Estruturar a nossa rede neural\n",
        "# - Treinar o modelo\n",
        "# - Fazer as previsões"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0AEHNKDZvUX"
      },
      "source": [
        "# Achatando a matriz de pixels e transformando em uma única lista\n",
        "\n",
        "quantidade_treino = len(x_treino) # 60000\n",
        "quantidade_teste = len(x_teste) # 10000\n",
        "\n",
        "resolucao_imagem = x_treino[0].shape # (28, 28)\n",
        "resolucao_total = resolucao_imagem[0] * resolucao_imagem[1] # 28 * 28 = 784\n",
        "\n",
        "x_treino = x_treino.reshape(quantidade_treino, resolucao_total)\n",
        "x_teste = x_teste.reshape(quantidade_teste, resolucao_total)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHPxyKURb90u",
        "outputId": "a03775ba-2f32-4650-c172-d5beb4954985"
      },
      "source": [
        "print(\"Quantidade de itens em x_treino[0]:\", len(x_treino[0]))\n",
        "\n",
        "# Como ficou x_treino[0]?\n",
        "print(x_treino[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de itens em x_treino[0]: 784\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2BoM-DOc0ia",
        "outputId": "1a3df215-ba8d-4572-f81f-254632076ec5"
      },
      "source": [
        "# Normalização dos dados\n",
        "\n",
        "# 255 vira 1\n",
        "# 127 vira 0.5\n",
        "# 0 vira 0\n",
        "# E assim por diante\n",
        "\n",
        "# Precisamos garantir que o valor máximo de entrada é 1\n",
        "# Como atualmente a imagem fornece um valor máximo de 255, precisamos normalizá-los\n",
        "\n",
        "x_treino = x_treino.astype('float32')\n",
        "x_teste = x_teste.astype('float32')\n",
        "\n",
        "x_treino /= 255\n",
        "x_teste /= 255\n",
        "\n",
        "print(x_treino[0][350], type(x_treino[0][350]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.27450982 <class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7YyBi-qfUmU",
        "outputId": "678572be-20c0-4759-f1dd-6389fc166e58"
      },
      "source": [
        "# Visualizando os dados normalizados\n",
        "\n",
        "print(\"Dados normalizados:\", x_treino[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dados normalizados: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUZOraROig58",
        "outputId": "722c05e6-f02c-4c89-d513-64b44415c983"
      },
      "source": [
        "# Preparação da camada de saída (output)\n",
        "\n",
        "valores_unicos = set(y_treino) # {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
        "print(valores_unicos)\n",
        "\n",
        "quantidade_valores_unicos = len(valores_unicos) # 10\n",
        "print(quantidade_valores_unicos)\n",
        "\n",
        "# Transformar os valores únicos em variáveis categóricas\n",
        "# Número 0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "# Número 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "# ...\n",
        "# Número 9 -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
        "\n",
        "print(\"y_treino[0] antes:\", y_treino[0])\n",
        "\n",
        "y_treino = keras.utils.to_categorical(y_treino, quantidade_valores_unicos)\n",
        "y_teste = keras.utils.to_categorical(y_teste, quantidade_valores_unicos)\n",
        "\n",
        "print(\"y_treino[0] depois:\", y_treino[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "10\n",
            "y_treino[0] antes: 5\n",
            "y_treino[0] depois: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WifnGG1k_Fv",
        "outputId": "a01121b8-a1e6-4fa7-d536-7f03238340ed"
      },
      "source": [
        "# Criando o modelo da rede neural\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Primeira hidden layer\n",
        "# 30 neurônios\n",
        "# Função de ativação: ReLU\n",
        "# Como estamos na primeira hidden layer, precisamos informar o formato da camada de entrada (input)\n",
        "\n",
        "model.add(Dense(30, activation='relu', input_shape=(resolucao_total,)))\n",
        "\n",
        "# Adicionamos um regularizador, que ajuda a evitar o overfitting\n",
        "# No caso, será o Dropout\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Segunda hidden layer\n",
        "# 20 neurônios\n",
        "# Função de ativação: ReLU\n",
        "model.add(Dense(20, activation='relu'))\n",
        "\n",
        "# Mais um regularizador depois da segunda hidden layer\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Finalizamos com a camada de saída (output), informando a quantidade de valores únicos, que no caso é 10\n",
        "model.add(Dense(quantidade_valores_unicos, activation='softmax'))\n",
        "\n",
        "# Exibe o resumo do modelo criado\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 24,380\n",
            "Trainable params: 24,380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBVqvhwXnlOV"
      },
      "source": [
        "# Compila o modelo\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS1epHAhn1hQ",
        "outputId": "9b5c4cf3-3746-46e6-ee66-32ef7f02d005"
      },
      "source": [
        "# Treina o modelo\n",
        "\n",
        "history = model.fit(x_treino, y_treino,\n",
        "                    batch_size=128,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_teste, y_teste))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.8441 - accuracy: 0.7356 - val_loss: 0.2929 - val_accuracy: 0.9183\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.8653 - val_loss: 0.2312 - val_accuracy: 0.9334\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3789 - accuracy: 0.8879 - val_loss: 0.2071 - val_accuracy: 0.9387\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3462 - accuracy: 0.8977 - val_loss: 0.1959 - val_accuracy: 0.9407\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.9038 - val_loss: 0.1889 - val_accuracy: 0.9433\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3126 - accuracy: 0.9080 - val_loss: 0.1803 - val_accuracy: 0.9463\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2974 - accuracy: 0.9120 - val_loss: 0.1700 - val_accuracy: 0.9504\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2853 - accuracy: 0.9158 - val_loss: 0.1708 - val_accuracy: 0.9492\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.9187 - val_loss: 0.1625 - val_accuracy: 0.9544\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.9196 - val_loss: 0.1628 - val_accuracy: 0.9531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "e8DoDpq6pneo",
        "outputId": "ef73dd9c-f614-4896-9dd8-abf1c2a84e51"
      },
      "source": [
        "# Fazendo nossas previsões\n",
        "\n",
        "indice = 100\n",
        "\n",
        "print(\"Valor categórico em y_teste[indice]:\", y_teste[indice])\n",
        "\n",
        "# Preparar a imagem para fazer a previsão\n",
        "imagem = x_teste[indice].reshape((1, resolucao_total))\n",
        "\n",
        "prediction = model.predict(imagem)\n",
        "print(\"Previsão:\", prediction)\n",
        "\n",
        "# Transformar a previsão em algo que conseguimos entender\n",
        "\n",
        "import numpy as np\n",
        "prediction_class = np.argmax(prediction, axis=-1)\n",
        "print(\"Previsão ajustada:\", prediction_class)\n",
        "\n",
        "# Apenas para visualizar a imagem\n",
        "(x_treino_img, y_treino_img), (x_teste_img, y_teste_img) = mnist.load_data()\n",
        "plt.imshow(x_teste_img[indice], cmap=plt.cm.binary)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor categórico em y_teste[indice]: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "Previsão: [[2.3977978e-05 2.1811927e-07 6.0842826e-04 1.7403845e-08 6.5760687e-05\n",
            "  4.5828612e-05 9.9920928e-01 1.2604046e-07 4.6288766e-05 2.3100928e-09]]\n",
            "Previsão ajustada: [6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5fe836c8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}